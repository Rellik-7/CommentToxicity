# CommentToxicity

This project uses the comment toxicity classification dataset of Jigsaw, from Kaggle.
Link: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data

I have used a bi-directional LSTM network, with multi-binary outputs to classify comments as any of the following:

toxic
severe_toxic
obscene
threat
insult
identity_hate
